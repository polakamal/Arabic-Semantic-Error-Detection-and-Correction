{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNrazYeKlqvgsdxLaH7HWXP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polakamal/Arabic-Semantic-Error-Detection-and-Correction/blob/main/LSTMproj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9_O5v_SKtRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19dff3b-ffc0-4d9b-d647-2ccbfc160333"
      },
      "source": [
        "pip install jiwer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer) (57.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKVJiv-_muqL",
        "outputId": "a1b0a78a-1456-4f78-bc87-671d4496f39b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eAlBlXBmyjJ",
        "outputId": "82bc59ca-6e86-49a3-ce16-bcf554d080d6"
      },
      "source": [
        "# Check we have a GPU and check the memory size of the GUP\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun  6 22:19:54 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DthaBm3Fm0FS",
        "outputId": "10368395-741e-4539-9f83-c2ebe4d42f40"
      },
      "source": [
        "from nltk import  word_tokenize,sent_tokenize\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "pd.set_option(\"display.max_colwidth\", -1)\n",
        "nltk.download('punkt')\n",
        "punctuations = set(string.punctuation)\n",
        "punctuations.update('‘','’','،','؛','؟')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPbbIOWm0Ic"
      },
      "source": [
        "def extract_data(file_name):\n",
        "  sentence = []\n",
        "  corrected= []\n",
        "  f = open(file_name, \"r\", encoding=\"utf8\")\n",
        "  for l in f:\n",
        "        if l.startswith('S '):\n",
        "            sentence.append(' '.join(l.split()[1:]))\n",
        "            corrected.append(\"[br]\")\n",
        "        if l.startswith('A '):\n",
        "            corrected.append(' '.join(l.split()[1:]))\n",
        "  data = extract_corrected_sent(sentence,corrected)\n",
        "  return  data  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H3Bv_V-m0Kt"
      },
      "source": [
        "def extract_corrected_sent(sentence,corrected_sent):\n",
        "  data=[]\n",
        "  count=0\n",
        "  counter=0\n",
        "  para =''\n",
        "  sample= ''\n",
        "  add_b_action = 'Add_before'\n",
        "  merge_action='Merge'\n",
        "  split_action='Split'\n",
        "  delete_action='Delete'\n",
        "  other_action='Other'\n",
        "  add_a_action ='Add_after'\n",
        "  delete_token = 'delete_token'\n",
        "  add_token_before = 'add_token_before'\n",
        "  add_token_after='add_token_after'\n",
        "  splitInsert4tokens='splitInsert4tokens'\n",
        "  splitInsert3tokens='splitInsert3tokens'\n",
        "  split_merge='split_merge'\n",
        "  merge_split='merge-split'\n",
        "  for i in corrected_sent:\n",
        "     if i == '[br]':\n",
        "         counter=0\n",
        "         para= sentence[count]\n",
        "         if count==0:\n",
        "            data.append([sentence[count],sample])\n",
        "         else:\n",
        "            data.append([sentence[count-1],sample]) \n",
        "         count=count+1\n",
        "         continue     \n",
        "     \n",
        "     fields=i.split('|||')\n",
        "     start_offset = int(fields[0].split()[0])\n",
        "     end_offset = int(fields[0].split()[1])\n",
        "     word= fields[2]\n",
        "     action= fields[1]\n",
        "     #print(\"before :    \"+para )\n",
        "     #print(counter)\n",
        "     #print(action)   \n",
        "     sample = correted_sentence_data(para ,action ,start_offset+counter,end_offset+counter,word)\n",
        "     if add_a_action ==action or add_b_action ==action or split_action ==action or add_token_before==action or add_token_after==action or split_action.lower()==action:\n",
        "       counter =counter+1\n",
        "     elif  merge_action==action or delete_action==action or delete_token==action or merge_action.lower()==action :\n",
        "         counter =counter-1 \n",
        "     elif other_action==action or splitInsert4tokens ==action or splitInsert3tokens ==action or split_merge==action:\n",
        "         if  end_offset - start_offset == 1 :\n",
        "            counter =counter +(len(word_tokenize(word))-1)\n",
        "         elif  end_offset - start_offset != len(word_tokenize(word)):\n",
        "           counter =counter - (end_offset - start_offset)\n",
        "           counter =counter + len(word_tokenize(word))\n",
        "\n",
        "     para = sample  \n",
        "     #print(\"after :    \"+para )\n",
        "    \n",
        "     #print(\"________________________________________________________________________________________________ \" )\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d24SlAiJm0NH"
      },
      "source": [
        "def correted_sentence_data(para ,action ,start_offset,end_offset,changed_word):\n",
        "  action1 ='Add_before'\n",
        "  action2='Merge'\n",
        "  action3='Split'\n",
        "  action4='Delete'\n",
        "  action5 = 'Edit'\n",
        "  action6='Other'\n",
        "  action7='Move'\n",
        "  action8 ='Add_after'\n",
        "  delete_token = 'delete_token'\n",
        "  add_token_before = 'add_token_before'\n",
        "  add_token_after='add_token_after'\n",
        "  move_before='move_before'\n",
        "  splitInsert4tokens='splitInsert4tokens'\n",
        "  splitInsert3tokens='splitInsert3tokens'\n",
        "  split_merge='split_merge'\n",
        "  merge_split='merge-split'\n",
        "  sent= ''\n",
        "  counter = 0\n",
        "  sample = word_tokenize(para)\n",
        "  if action1 == action or add_token_before==action:\n",
        "           sample.insert(start_offset ,changed_word)\n",
        "           sent= ' '.join(word for word in sample)\n",
        "           \n",
        "  elif action6 ==action  or splitInsert4tokens ==action or splitInsert3tokens ==action or split_merge==action or merge_split==action:\n",
        "    if  end_offset - start_offset > 1 :\n",
        "      for i in range(end_offset - start_offset):\n",
        "           sample.pop(start_offset)\n",
        "        \n",
        "      sample.insert(start_offset,changed_word)\n",
        "      sent= ' '.join(word for word in sample)\n",
        "    else:  \n",
        "           sample.pop(start_offset)\n",
        "           sample.insert(start_offset,changed_word)\n",
        "           sent= ' '.join(word for word in sample)\n",
        " \n",
        "  elif action2 == action  or action7==action or move_before==action or action2.lower() == action:\n",
        "           sample.pop(start_offset)\n",
        "           sample.pop(start_offset)\n",
        "           sample.insert(start_offset,changed_word)\n",
        "           sent= ' '.join(word for word in sample)\n",
        "  elif  action3 == action or action3.lower()==action  :\n",
        "           sample.pop(start_offset)\n",
        "           sample.insert(start_offset,changed_word)\n",
        "           sent= ' '.join(word for word in sample)\n",
        "  elif action4 == action or delete_token==action:\n",
        "           sample.pop(start_offset)\n",
        "           sent= ' '.join(word for word in sample) \n",
        "  elif action5 == action or action5.lower()==action: \n",
        "           \n",
        "           sample[start_offset] =changed_word\n",
        "           sent= ' '.join(word for word in sample)\n",
        "           #print(\"inside the edit\",sent)\n",
        "  elif action8==action or add_token_after==action:\n",
        "          sample.insert(end_offset ,changed_word)\n",
        "          sent= ' '.join(word for word in sample)    \n",
        "           #print(\"________________________________________________________________________________________________ \" )\n",
        "  #print(\"after :    \"+sent )     \n",
        "  return sent "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxzygwuWm8ry"
      },
      "source": [
        "train = extract_data(\"/content/drive/MyDrive/NlpProject/data/QALB-Train2014.m2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoVo7tivm8xW",
        "outputId": "b05d102f-ebca-4749-e566-8077fae91258"
      },
      "source": [
        "train.pop(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['الى التعليق رقم 2 اكيد ان لحكام العرب والمسلمين مسؤولية يتمثل ادناها في استدعاء السفراء في الصين للتشاور . فليتهم يفعلونها ولو مرة . ولنا نحن كشعوب مسؤولية كذالك تتمثل في مساندة اخواننا في الصين بمقاطعة البضائع الصينينة وليتنا نفعلها ولو ثلاتة اشهر .',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qix5FDVom80c"
      },
      "source": [
        "df_train =  pd.DataFrame(train ,columns=['sentence','corrected'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXR2S4Ajm0PW"
      },
      "source": [
        "vald = extract_data(\"/content/drive/MyDrive/NlpProject/data/QALB-Dev2014.m2\")\n",
        "test = extract_data(\"/content/drive/MyDrive/NlpProject/data/QALB-Test2014.m2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhbYW0Kym0R1",
        "outputId": "93448cca-29a9-459b-d86d-9efa187e8201"
      },
      "source": [
        "vald.pop(0)\n",
        "test.pop(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['لا زال كبير الشبيحه يظن ان ارواح وآلام الناس اقل كلفه من تخليه عن منصبه ، فلذلك اذا كان السوريون لا يرتضون بهذه المعادله المهينه ، فعليهم ان يهبوا هبه قويه واحده وياخذو حقوقهم من هذه العصابه عنوه ، اننا يا أحبائي ندفع ثمن اكثر من اربعين عام ومن الخنوع والذل والثمن سيكون غاليا ولكنه يستأهل هذه التضحيات',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5nnrmQRm0T5"
      },
      "source": [
        "df_vald=  pd.DataFrame(vald ,columns=['sentence','corrected'])\n",
        "df_test =  pd.DataFrame(test ,columns=['sentence','corrected'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fg31wifnFqK",
        "outputId": "45f947ee-6917-4ac1-a684-233185801b20"
      },
      "source": [
        "df_vald.size,df_test.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2032, 1934)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajZ4RTNXnFtC"
      },
      "source": [
        "def preprocessing(text):\n",
        "  for punctuation in punctuations:\n",
        "        text = text.replace(punctuation,'') \n",
        "  text=re.sub('\\d+','',text)\n",
        "  text=re.sub(r'\\. \\.+','',text)\n",
        "  text=re.sub(r'[\\`|\\\"|\\(|\\)|\\%|\\[|\\]\\_\\-\\*\\&\\@\\?\\!]','',text)\n",
        "  text= re.sub(' +',' ',text)\n",
        "  text=text.strip()\n",
        "  return text "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww9psA_9nFvI"
      },
      "source": [
        "df_train['sentence'] = df_train['sentence'].apply(lambda x: preprocessing( x ) )\n",
        "df_train['corrected'] = df_train['corrected'].apply(lambda x: preprocessing( x ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTnIi8mPnFxN"
      },
      "source": [
        "df_vald['sentence'] = df_vald['sentence'].apply(lambda x: preprocessing( x ) )\n",
        "df_vald['corrected'] = df_vald['corrected'].apply(lambda x: preprocessing( x ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crPhKYxknF0b"
      },
      "source": [
        "df_test['sentence'] = df_test['sentence'].apply(lambda x: preprocessing( x ) )\n",
        "df_test['corrected'] = df_test['corrected'].apply(lambda x: preprocessing( x ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "c6F0PYHSnF2X",
        "outputId": "ca415223-6e50-451f-addb-7af2b863b64f"
      },
      "source": [
        "df_train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corrected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>الى التعليق رقم اكيد ان لحكام العرب والمسلمين مسؤولية يتمثل ادناها في استدعاء السفراء في الصين للتشاور فليتهم يفعلونها ولو مرة ولنا نحن كشعوب مسؤولية كذالك تتمثل في مساندة اخواننا في الصين بمقاطعة...</td>\n",
              "      <td>إلى التعليق رقم أكيد أن للحكام العرب والمسلمين مسؤولية يتمثل أدناها في استدعاء السفراء في الصين للتشاور فليتهم يفعلونها ولو مرة ولنا نحن كشعوب مسؤولية كذلك تتمثل في مساندة إخواننا في الصين بمقاطعة...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>نحن ببالغ الاسى نعزي ضحايا الحادث الاليم الذي ذهب ضحيته حوالي ما بين جريح ومتوفي واطالب من سلطات بلادي ان تطبق القانون بصرامة وتضرب بيد من حديد مثل هؤلاء المجرمين والمتهورين والمتسببين في مثل هذه ...</td>\n",
              "      <td>نحن ببالغ الأسى نعزي ضحايا الحادث الأليم الذي ذهب ضحيته حوالي ما بين جريح ومتوفي وأطالب من سلطات بلادي أن تطبق القانون بصرامة وتضرب بيد من حديد مثل هؤلاء المجرمين والمتهورين والمتسببين في مثل هذه ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>للاسف ان الدم المهدور عراقي لكن بشكل عام لماذا الاتهام من قبل الاعلام الغربي والعربي للقاعدة والتطرف والناس المتسللة من دول الجوار فقط هل اصبح العراقيون جميعهم بلا دم واحساس وادناب للامريكان ولا ا...</td>\n",
              "      <td>للأسف إن الدم المهدور عراقي لكن بشكل عام لماذا الاتهام من قبل الإعلام الغربي والعربي للقاعدة والتطرف والناس المتسللة من دول الجوار فقط هل أصبح العراقيون جميعهم بلا دم وإحساس وأذنابا للأمريكان ولا ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>واصل الثوار أنتصاراتهم وحررو كل حقول النفط السورية لهذا السبب قام النظام اللبناني الخائن بمساعدة نظام الاسد بالبنزين والمازوت منتهكآ العقوبات المفروضة على النظام ولكن الثوار قررو قطع الطريق بين دم...</td>\n",
              "      <td>واصل الثوار انتصاراتهم وحرروا كل حقول النفط السورية لهذا السبب قام النظام اللبناني الخائن بمساعدة نظام الأسد بالبنزين والمازوت منتهكا العقوبات المفروضة على النظام ولكن الثوار قرروا قطع الطريق بين ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>يا حرام على ما يدعو نفسهم شبيحة الأسد وحزب الله بعد ان ارسلهم عميل الصهاينة المستعرب خامنئي الجزار لقتل أهلهم وخدمة لمصالح وطموح ايران بالسيطرة على بلاد الشام ولكنهم أكتشفوا ان موتهم ونهايتهم في د...</td>\n",
              "      <td>يا حرام على من يدعون نفسهم شبيحة الأسد وحزب الله بعد أن أرسلهم عميل الصهاينة المستعرب خامنئي الجزار لقتل أهلهم وخدمة لمصالح وطموح إيران بالسيطرة على بلاد الشام ولكنهم اكتشفوا أن موتهم ونهايتهم في ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>اليوم المظاهرات الحاشدة تعتبر جمعة مفصلية تاريخية حيث حظي المجلس بتاييد شعبي واسع وايضا ظهر ان بشار والة القتل عجزت عن مواجهة الشعب السوري بل ان باعتقادي ان بشار سينهار قريبا فالجزيرة نقلت عن ميدف...</td>\n",
              "      <td>اليوم المظاهرات الحاشدة تعتبر جمعة مفصلية تاريخية حيث حظي المجلس بتأييد شعبي واسع وأيضا ظهر أن بشار وآلة القتل عجزت عن مواجهة الشعب السوري بل إن باعتقادي أن بشار سينهار قريبا فالجزيرة نقلت عن ميدف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>وقف اطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف اطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف اطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف اطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة</td>\n",
              "      <td>وقف إطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف إطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف إطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف إطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>إلى الإخوة في الجزيرة هؤلاء شهداء وهم خيرة الشهداء وهم ليسوا قتلى عاديين أرجو الله أن يكونوا في منزلة خيرة شهداء هذه الأمة أمثال حمزة وعمر وعلي والحسين نرجو وصفهم بالشهداء وليسوا بالقتلى وذلك إحتر...</td>\n",
              "      <td>إلى الإخوة في الجزيرة هؤلاء شهداء وهم خيرة الشهداء وهم ليسوا قتلى عاديين أرجو الله أن يكونوا في منزلة خيرة شهداء هذه الأمة أمثال حمزة وعمر وعلى والحسين نرجو وصفهم بالشهداء وليس بالقتلى وذلك احترام...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>مصير جميع الإرهابيين السحق على يد الجيش التركي ومن يقول لماذا لايقوم الجيش التركي بالقضاء التام على الإرهابيين من حزب العمال كما فعل صدام أقول له أن الجيش التركي يراعي ظروف المنطقة واختباء الإرهاب...</td>\n",
              "      <td>مصير جميع الإرهابيين السحق على يد الجيش التركي ومن يقول لماذا لا يقوم الجيش التركي بالقضاء التام على الإرهابيين من حزب العمال كما فعل صدام أقول له أن الجيش التركي يراعي ظروف المنطقة واختباء الإرها...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ثورة الآخرين على ارض الشام حيث ان الجيش الحر يستجلب ما هب ودب من مقاتلين اجانب ليقاتلوا نيابة عن الشعب السوري وهذه الثورة تعتبر فاشلة لانها لا توصل الا لهدف تدمير سوريا من الداخل لان الشعب السوري ...</td>\n",
              "      <td>ثورة الآخرين على أرض الشام حيث أن الجيش الحر يستجلب ما هب ودب من مقاتلين أجانب ليقاتلوا نيابة عن الشعب السوري وهذه الثورة تعتبر فاشلة لأنها لا توصل إلا لهدف تدمير سوريا من الداخل لأن الشعب السوري ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                  sentence                                                                                                                                                                                                corrected\n",
              "0  الى التعليق رقم اكيد ان لحكام العرب والمسلمين مسؤولية يتمثل ادناها في استدعاء السفراء في الصين للتشاور فليتهم يفعلونها ولو مرة ولنا نحن كشعوب مسؤولية كذالك تتمثل في مساندة اخواننا في الصين بمقاطعة...  إلى التعليق رقم أكيد أن للحكام العرب والمسلمين مسؤولية يتمثل أدناها في استدعاء السفراء في الصين للتشاور فليتهم يفعلونها ولو مرة ولنا نحن كشعوب مسؤولية كذلك تتمثل في مساندة إخواننا في الصين بمقاطعة...\n",
              "1  نحن ببالغ الاسى نعزي ضحايا الحادث الاليم الذي ذهب ضحيته حوالي ما بين جريح ومتوفي واطالب من سلطات بلادي ان تطبق القانون بصرامة وتضرب بيد من حديد مثل هؤلاء المجرمين والمتهورين والمتسببين في مثل هذه ...  نحن ببالغ الأسى نعزي ضحايا الحادث الأليم الذي ذهب ضحيته حوالي ما بين جريح ومتوفي وأطالب من سلطات بلادي أن تطبق القانون بصرامة وتضرب بيد من حديد مثل هؤلاء المجرمين والمتهورين والمتسببين في مثل هذه ...\n",
              "2  للاسف ان الدم المهدور عراقي لكن بشكل عام لماذا الاتهام من قبل الاعلام الغربي والعربي للقاعدة والتطرف والناس المتسللة من دول الجوار فقط هل اصبح العراقيون جميعهم بلا دم واحساس وادناب للامريكان ولا ا...  للأسف إن الدم المهدور عراقي لكن بشكل عام لماذا الاتهام من قبل الإعلام الغربي والعربي للقاعدة والتطرف والناس المتسللة من دول الجوار فقط هل أصبح العراقيون جميعهم بلا دم وإحساس وأذنابا للأمريكان ولا ...\n",
              "3  واصل الثوار أنتصاراتهم وحررو كل حقول النفط السورية لهذا السبب قام النظام اللبناني الخائن بمساعدة نظام الاسد بالبنزين والمازوت منتهكآ العقوبات المفروضة على النظام ولكن الثوار قررو قطع الطريق بين دم...  واصل الثوار انتصاراتهم وحرروا كل حقول النفط السورية لهذا السبب قام النظام اللبناني الخائن بمساعدة نظام الأسد بالبنزين والمازوت منتهكا العقوبات المفروضة على النظام ولكن الثوار قرروا قطع الطريق بين ...\n",
              "4  يا حرام على ما يدعو نفسهم شبيحة الأسد وحزب الله بعد ان ارسلهم عميل الصهاينة المستعرب خامنئي الجزار لقتل أهلهم وخدمة لمصالح وطموح ايران بالسيطرة على بلاد الشام ولكنهم أكتشفوا ان موتهم ونهايتهم في د...  يا حرام على من يدعون نفسهم شبيحة الأسد وحزب الله بعد أن أرسلهم عميل الصهاينة المستعرب خامنئي الجزار لقتل أهلهم وخدمة لمصالح وطموح إيران بالسيطرة على بلاد الشام ولكنهم اكتشفوا أن موتهم ونهايتهم في ...\n",
              "5  اليوم المظاهرات الحاشدة تعتبر جمعة مفصلية تاريخية حيث حظي المجلس بتاييد شعبي واسع وايضا ظهر ان بشار والة القتل عجزت عن مواجهة الشعب السوري بل ان باعتقادي ان بشار سينهار قريبا فالجزيرة نقلت عن ميدف...  اليوم المظاهرات الحاشدة تعتبر جمعة مفصلية تاريخية حيث حظي المجلس بتأييد شعبي واسع وأيضا ظهر أن بشار وآلة القتل عجزت عن مواجهة الشعب السوري بل إن باعتقادي أن بشار سينهار قريبا فالجزيرة نقلت عن ميدف...\n",
              "6  وقف اطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف اطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف اطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف اطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة  وقف إطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف إطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف إطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة وقف إطلاق الصواريخ من غزة مقابل رفع الحصار عن غزة\n",
              "7  إلى الإخوة في الجزيرة هؤلاء شهداء وهم خيرة الشهداء وهم ليسوا قتلى عاديين أرجو الله أن يكونوا في منزلة خيرة شهداء هذه الأمة أمثال حمزة وعمر وعلي والحسين نرجو وصفهم بالشهداء وليسوا بالقتلى وذلك إحتر...  إلى الإخوة في الجزيرة هؤلاء شهداء وهم خيرة الشهداء وهم ليسوا قتلى عاديين أرجو الله أن يكونوا في منزلة خيرة شهداء هذه الأمة أمثال حمزة وعمر وعلى والحسين نرجو وصفهم بالشهداء وليس بالقتلى وذلك احترام...\n",
              "8  مصير جميع الإرهابيين السحق على يد الجيش التركي ومن يقول لماذا لايقوم الجيش التركي بالقضاء التام على الإرهابيين من حزب العمال كما فعل صدام أقول له أن الجيش التركي يراعي ظروف المنطقة واختباء الإرهاب...  مصير جميع الإرهابيين السحق على يد الجيش التركي ومن يقول لماذا لا يقوم الجيش التركي بالقضاء التام على الإرهابيين من حزب العمال كما فعل صدام أقول له أن الجيش التركي يراعي ظروف المنطقة واختباء الإرها...\n",
              "9  ثورة الآخرين على ارض الشام حيث ان الجيش الحر يستجلب ما هب ودب من مقاتلين اجانب ليقاتلوا نيابة عن الشعب السوري وهذه الثورة تعتبر فاشلة لانها لا توصل الا لهدف تدمير سوريا من الداخل لان الشعب السوري ...  ثورة الآخرين على أرض الشام حيث أن الجيش الحر يستجلب ما هب ودب من مقاتلين أجانب ليقاتلوا نيابة عن الشعب السوري وهذه الثورة تعتبر فاشلة لأنها لا توصل إلا لهدف تدمير سوريا من الداخل لأن الشعب السوري ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3CYX9Vwh1uy"
      },
      "source": [
        "sents=[]\n",
        "for i in df_train['sentence']:\n",
        "  sent = word_tokenize(i)\n",
        "  sents.append(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIBKnQMDlMI2"
      },
      "source": [
        "correct=[]\n",
        "for i in df_train['corrected']:\n",
        "  sent = word_tokenize(i)\n",
        "  correct.append(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXwWfLCwiJME"
      },
      "source": [
        "max_text_len = max( [len(i) for i in sents] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhF10h7riJI2",
        "outputId": "74a22da0-91f8-4ce7-f7bf-d8b9f51e479f"
      },
      "source": [
        "max_text_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "169"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCh2F2AClRYj"
      },
      "source": [
        "max_summary_len = max( [len(i) for i in correct] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDdpC3Dvld35",
        "outputId": "610ca2b0-f6cd-4804-b465-1bab610294da"
      },
      "source": [
        "max_summary_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYC7-TDZnF5N"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM,Input,TimeDistributed,Bidirectional,Concatenate\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import regularizers\n",
        "from keras import backend as K \n",
        "from keras import optimizers\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbqbC8ogns5d"
      },
      "source": [
        "df_train['corrected'] = df_train['corrected'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
        "df_vald['corrected']= df_vald['corrected'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
        "df_test['corrected']= df_test['corrected'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dNYTswIaeU5"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(df_vald['sentence'].append(df_train['sentence'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu2jvRj7aeX6",
        "outputId": "e5736dfc-2dfd-4143-a145-ed778ff18ef5"
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 67.40772673153508\n",
            "Total Coverage of rare words: 7.761759539810238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORRjLFlnaehJ",
        "outputId": "cff2b9a3-5c30-4e7d-da50-c8e3d44b7ccb"
      },
      "source": [
        "x_tokenizer = Tokenizer(num_words=tot_cnt) \n",
        "x_tokenizer.fit_on_texts(list(df_vald['sentence'].append(df_train['sentence'])))\n",
        "\n",
        "#convert text sequences into integer sequences (i.e one-hot encodeing all the words)\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(df_train['sentence']) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(df_vald['sentence'])\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary in X = 146143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyrnH2FGaekG"
      },
      "source": [
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(df_vald['corrected'].append(df_train['corrected'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAAXJEvNaemQ",
        "outputId": "2d7b2c98-8cca-4022-9898-6219f88b0f2a"
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 77.55060146980334\n",
            "Total Coverage of rare words: 10.870317326704372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aor62itacWFA",
        "outputId": "6408f76f-c27c-42e5-f792-b02e6b2edc55"
      },
      "source": [
        "y_tokenizer = Tokenizer(num_words=tot_cnt) \n",
        "y_tokenizer.fit_on_texts(list(df_vald['corrected'].append(df_train['corrected'])))\n",
        "\n",
        "#convert text sequences into integer sequences (i.e one hot encode the text in Y)\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(df_train['corrected']) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(df_vald['corrected']) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary in Y = 146143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjuhxm4ziFtB"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "        \n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMiX86Y0iGMQ"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsg8V-hMnGFR",
        "outputId": "68c68f9d-b8cb-4d87-be6c-72a4c50501c1"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Total params: 105,091,043\n",
            "Trainable params: 105,091,043\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O46pNdC2nGIw"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "#optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQpT7Syr1jsH"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmB-WAbX1lru",
        "outputId": "e096895f-f254-45a5-e31a-abe94ea8be38"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=30,batch_size=32,validation_data= ([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "607/607 [==============================] - 334s 541ms/step - loss: 5.1128 - accuracy: 0.4856 - val_loss: 4.6260 - val_accuracy: 0.4957\n",
            "Epoch 2/30\n",
            "607/607 [==============================] - 328s 541ms/step - loss: 4.4859 - accuracy: 0.5002 - val_loss: 4.4678 - val_accuracy: 0.5039\n",
            "Epoch 3/30\n",
            "607/607 [==============================] - 328s 540ms/step - loss: 4.2702 - accuracy: 0.5112 - val_loss: 4.3393 - val_accuracy: 0.5142\n",
            "Epoch 4/30\n",
            "607/607 [==============================] - 328s 541ms/step - loss: 4.0574 - accuracy: 0.5214 - val_loss: 4.2492 - val_accuracy: 0.5200\n",
            "Epoch 5/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 3.8581 - accuracy: 0.5290 - val_loss: 4.2071 - val_accuracy: 0.5230\n",
            "Epoch 6/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 3.6677 - accuracy: 0.5365 - val_loss: 4.1711 - val_accuracy: 0.5259\n",
            "Epoch 7/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 3.4831 - accuracy: 0.5433 - val_loss: 4.1627 - val_accuracy: 0.5271\n",
            "Epoch 8/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 3.3078 - accuracy: 0.5502 - val_loss: 4.1643 - val_accuracy: 0.5291\n",
            "Epoch 9/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 3.1356 - accuracy: 0.5569 - val_loss: 4.1809 - val_accuracy: 0.5297\n",
            "Epoch 10/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 2.9671 - accuracy: 0.5653 - val_loss: 4.2055 - val_accuracy: 0.5297\n",
            "Epoch 11/30\n",
            "607/607 [==============================] - 328s 540ms/step - loss: 2.8024 - accuracy: 0.5790 - val_loss: 4.2277 - val_accuracy: 0.5313\n",
            "Epoch 12/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 2.6439 - accuracy: 0.5977 - val_loss: 4.2630 - val_accuracy: 0.5315\n",
            "Epoch 13/30\n",
            "607/607 [==============================] - 327s 540ms/step - loss: 2.4978 - accuracy: 0.6147 - val_loss: 4.2971 - val_accuracy: 0.5314\n",
            "Epoch 14/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 2.3669 - accuracy: 0.6296 - val_loss: 4.3252 - val_accuracy: 0.5312\n",
            "Epoch 15/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 2.2514 - accuracy: 0.6433 - val_loss: 4.3593 - val_accuracy: 0.5305\n",
            "Epoch 16/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 2.1480 - accuracy: 0.6558 - val_loss: 4.3916 - val_accuracy: 0.5308\n",
            "Epoch 17/30\n",
            "607/607 [==============================] - 327s 538ms/step - loss: 2.0541 - accuracy: 0.6676 - val_loss: 4.4205 - val_accuracy: 0.5307\n",
            "Epoch 18/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 1.9677 - accuracy: 0.6788 - val_loss: 4.4541 - val_accuracy: 0.5293\n",
            "Epoch 19/30\n",
            "607/607 [==============================] - 327s 538ms/step - loss: 1.8874 - accuracy: 0.6893 - val_loss: 4.4887 - val_accuracy: 0.5295\n",
            "Epoch 20/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 1.8121 - accuracy: 0.6994 - val_loss: 4.5198 - val_accuracy: 0.5286\n",
            "Epoch 21/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 1.7429 - accuracy: 0.7090 - val_loss: 4.5474 - val_accuracy: 0.5292\n",
            "Epoch 22/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 1.6769 - accuracy: 0.7182 - val_loss: 4.5836 - val_accuracy: 0.5277\n",
            "Epoch 23/30\n",
            "607/607 [==============================] - 328s 540ms/step - loss: 1.6153 - accuracy: 0.7269 - val_loss: 4.6156 - val_accuracy: 0.5277\n",
            "Epoch 24/30\n",
            "607/607 [==============================] - 328s 540ms/step - loss: 1.5569 - accuracy: 0.7354 - val_loss: 4.6427 - val_accuracy: 0.5277\n",
            "Epoch 25/30\n",
            "607/607 [==============================] - 327s 539ms/step - loss: 1.5022 - accuracy: 0.7436 - val_loss: 4.6729 - val_accuracy: 0.5270\n",
            "Epoch 26/30\n",
            "607/607 [==============================] - 328s 540ms/step - loss: 1.4502 - accuracy: 0.7514 - val_loss: 4.7069 - val_accuracy: 0.5274\n",
            "Epoch 27/30\n",
            "607/607 [==============================] - 329s 542ms/step - loss: 1.4017 - accuracy: 0.7586 - val_loss: 4.7305 - val_accuracy: 0.5274\n",
            "Epoch 28/30\n",
            "607/607 [==============================] - 328s 540ms/step - loss: 1.3545 - accuracy: 0.7659 - val_loss: 4.7648 - val_accuracy: 0.5263\n",
            "Epoch 29/30\n",
            "607/607 [==============================] - 329s 542ms/step - loss: 1.3098 - accuracy: 0.7730 - val_loss: 4.7898 - val_accuracy: 0.5260\n",
            "Epoch 30/30\n",
            "607/607 [==============================] - 329s 541ms/step - loss: 1.2676 - accuracy: 0.7797 - val_loss: 4.8193 - val_accuracy: 0.5257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP7GVE7d1vCi"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzsrlY1y1vHG"
      },
      "source": [
        "target_word_index = y_tokenizer.word_index\n",
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=y_tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVe71Cn12FV"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm4cJZFT12I9"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_text_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhgaooq888dT"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIfrS11V12LF",
        "outputId": "0e4b6d60-a5c0-47f2-c63e-01ba65bc9a3b"
      },
      "source": [
        "print(decode_sequence(x_tr[0].reshape(1,max_text_len)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " إلى التعليق رقم إن لم يكن مستغربا أن تنبري زمرة شهداء الذين يكتبون وينتقدون الجزيرة ويدافعون عن الظلم المسلط عليهم باسم الإسلام والمسلمين إلى متى نقول ونصنع لأنفسنا جوا خياليا نعيش في الأرض فسادا أين كنتم لا نريد من أي دولة مسلمة التي نشاهدها الله بإذن الله\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58yYm3ZI9BhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5114da3-3abd-4e2b-d9a8-1a9c66ace2f0"
      },
      "source": [
        "print(\"Original text:\",seq2text(x_tr[0]))\n",
        "print(\"corrected:\",seq2summary(y_tr[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: الى التعليق رقم اكيد ان لحكام العرب والمسلمين مسؤولية يتمثل ادناها في استدعاء السفراء في الصين للتشاور فليتهم يفعلونها ولو مرة ولنا نحن كشعوب مسؤولية كذالك تتمثل في مساندة اخواننا في الصين بمقاطعة البضائع الصينينة وليتنا نفعلها ولو ثلاتة اشهر \n",
            "corrected: إلى التعليق رقم أكيد أن للحكام العرب والمسلمين مسؤولية يتمثل أدناها في استدعاء السفراء في الصين للتشاور فليتهم يفعلونها ولو مرة ولنا نحن كشعوب مسؤولية كذلك تتمثل في مساندة إخواننا في الصين بمقاطعة البضائع الصينية وليتنا نفعلها ولو ثلاثة أشهر \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErA3Z5pVjjE8",
        "outputId": "86202f9f-4483-43cd-94db-84ddd4c582bc"
      },
      "source": [
        "print(decode_sequence(x_val[0].reshape(1,max_text_len)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " سبحان الله يرصدون أموال طائلة لمن يدمر على يد الشبيحة الذين يكتبون بأسماء من الكلية الحربية على الجيش السوري الحر بالموزاة مع بقية المناطق العربية لاتخاذ الوقت لزيارة ماهر الأسد بزيارة جبل الزاوية أكثر من نصف قرن من الجيش السوري بساحة مع من يقاتل بجيش المهدي إلى الآن\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7DZqMlK78dl",
        "outputId": "ba177574-d5ee-4bad-8735-d955744ad341"
      },
      "source": [
        "print(\"Original text:\",seq2text(x_val[0]))\n",
        "print(\"corrected:\",seq2summary(y_val[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: سبحان الله الحكام العرب سيموت على الكرسي ليضهر أنه عنيد وقوي لوكان بشار يحب أرضه أو شعبه لخرج من الحكم شفقة ورحمة ببلد ضاع هنا زال قناع هذا الرئيس اللذي خيب ظن شعبه والشعوب المسلمة كل مال السورين نفق في شراء سلاح ليقتل به شتانا وحكام أوربا الذين يتركون الكرسي لمجرد فتنة بسيطة لحبهم لبلدهم \n",
            "corrected: سبحان الله الحكام العرب سيموت على الكرسي ليظهر أنه عنيد وقوي لو كان بشار يحب أرضه أو شعبه لخرج من الحكم شفقة ورحمة ببلد ضاع هنا زال قناع هذا الرئيس الذى خيب ظن شعبه والشعوب المسلمة كل مال السورين نفق في شراء سلاح ليقتل به شتان وحكام أوربا الذين يتركون الكرسي لمجرد فتنة بسيطة لحبهم لبلدهم \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "bPExIMpIUoWL",
        "outputId": "1e4ca554-2a3d-4945-c509-737083a3a728"
      },
      "source": [
        "df_vald['corrected'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sostok سبحان الله الحكام العرب سيموت على الكرسي ليظهر أنه عنيد وقوي لو كان بشار يحب أرضه أو شعبه لخرج من الحكم شفقة ورحمة ببلد ضاع هنا زال قناع هذا الرئيس الذى خيب ظن شعبه والشعوب المسلمة كل مال السورين نفق في شراء سلاح ليقتل به شتان وحكام أوربا الذين يتركون الكرسي لمجرد فتنة بسيطة لحبهم لبلدهم eostok'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bSeQ86d6rz5"
      },
      "source": [
        "inputs=[]\n",
        "for i in  range (len(x_val)):\n",
        "    input =decode_sequence(x_val[i].reshape(1,max_text_len))\n",
        "    inputs.append(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUSKeL4t9hYE"
      },
      "source": [
        "from jiwer import wer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsKQH5nR6mz0"
      },
      "source": [
        "scores_wer=[]\n",
        "for i in range (len(inputs)):\n",
        "  w_e_r = wer(inputs[i],df_vald['corrected'][i]) \n",
        "  scores_wer.append(w_e_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv-1bJYYPxhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea45a22-ab75-4c59-8b92-00a7d7319aa5"
      },
      "source": [
        "np.mean(scores_wer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.065687944852582"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA1L9kGRae_G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}